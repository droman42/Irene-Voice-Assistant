# Voice Trigger Component Design
## –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –≥–æ–ª–æ—Å–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç

---

## üéØ **–¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ**

### –ê–Ω–∞–ª–∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã

**üî¥ Python Main Codebase: –ù–ï–¢ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –≥–æ–ª–æ—Å–∞**
- –û—Å–Ω–æ–≤–Ω–∞—è Python –∫–æ–¥–æ–≤–∞—è –±–∞–∑–∞ (`irene/`) –≤ –Ω–∞—Å—Ç–æ—è—â–µ–µ –≤—Ä–µ–º—è **–ù–ï –ò–ú–ï–ï–¢** –¥–µ—Ç–µ–∫—Ü–∏–∏ wake word
- `VoskRunner` –∏ `MicrophoneInput` –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—Ç **–Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏** - –æ–Ω–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç –í–°–ï –∞—É–¥–∏–æ –≤—Ö–æ–¥—ã –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
- –í—Å–µ –≥–æ–ª–æ—Å–æ–≤—ã–µ –≤—Ö–æ–¥—ã –∏–¥—É—Ç –Ω–∞–ø—Ä—è–º—É—é –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∫–æ–º–∞–Ω–¥

**‚úÖ ESP32 Firmware: –ü–û–õ–ù–ê–Ø –†–ï–ê–õ–ò–ó–ê–¶–ò–Ø**
- **–û—Å–Ω–æ–≤–Ω–æ–µ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ**: `ESP32/firmware/common/include/audio/wake_word_detector.hpp`
- **–†–µ–∞–ª–∏–∑–∞—Ü–∏—è**: `ESP32/firmware/common/src/audio/wake_word_detector.cpp`
- **–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è**: `ESP32/firmware/common/src/core/state_machine.cpp`
- **–§—É–Ω–∫—Ü–∏–∏**:
  - microWakeWord "medium-12-bn" –º–æ–¥–µ–ª—å —Å TensorFlow Lite Micro
  - –ü–µ—Ä-—É–∑–ª–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ wake word (–∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–æ –≤ `wake_word_training/`)
  - –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø–æ—Ä–æ–≥–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –∏ –∑–∞–¥–µ—Ä–∂–∫–∏
  - –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω —Å audio manager –∏ state machine

### –¢–µ–∫—É—â–∏–π –ø–æ—Ç–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏

```
üé§ Audio Input ‚Üí üó£Ô∏è VOSK ASR ‚Üí üìù ALL Text ‚Üí ‚ö° Command Processing
```

**–ß—Ç–æ –æ–∂–∏–¥–∞–µ—Ç—Å—è —Å VoiceTrigger:**
```
üé§ Audio Input ‚Üí üéº Workflow Orchestrator ‚Üí üëÇ Wake Word Detection ‚Üí [TRIGGERED] ‚Üí üó£Ô∏è ASR ‚Üí üìù Text ‚Üí ‚ö° Command Processing
                                       ‚Üí [NOT TRIGGERED] ‚Üí Continue listening
```

---

## üèóÔ∏è **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ**

### 1. –ß–∏—Å—Ç–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏

–°–ª–µ–¥—É—è –ø—Ä–∏–Ω—Ü–∏–ø–∞–º v13 –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã, **–∫–∞–∂–¥—ã–π —Å–ª–æ–π –∏–º–µ–µ—Ç –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—É—é –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å**:

```mermaid
graph TB
    subgraph "üì• Input Layer (Pure Audio Sources)"
        Mic[MicrophoneInput<br/>Just captures audio]
        WebAudio[WebAudioInput<br/>Just receives audio]
        FileAudio[FileAudioInput<br/>Just reads audio]
    end
    
    subgraph "üéØ Universal Plugins (Business Logic)"
        VT[UniversalVoiceTriggerPlugin<br/>Audio ‚Üí Wake Detection]
        ASR[UniversalASRPlugin<br/>Audio ‚Üí Text]
        LLM[UniversalLLMPlugin<br/>Text ‚Üí Response]
        TTS[UniversalTTSPlugin<br/>Text ‚Üí Audio]
    end
    
    subgraph "üéº Workflow Orchestration"
        VAWorkflow[VoiceAssistantWorkflowPlugin<br/>Orchestrates complete pipeline]
        ContWorkflow[ContinuousListeningWorkflowPlugin<br/>Direct ASR without wake word]
    end
    
    subgraph "üì§ Output Layer (Pure Output Targets)"
        Console[Console Output]
        Speaker[Audio Output]
        WebOut[Web Response]
    end
    
    Mic --> VAWorkflow
    WebAudio --> VAWorkflow
    FileAudio --> VAWorkflow
    
    Mic --> ContWorkflow
    WebAudio --> ContWorkflow
    
    VAWorkflow --> VT
    VAWorkflow --> ASR
    VAWorkflow --> LLM
    VAWorkflow --> TTS
    
    ContWorkflow --> ASR
    ContWorkflow --> LLM
    ContWorkflow --> TTS
    
    VAWorkflow --> Console
    VAWorkflow --> Speaker
    VAWorkflow --> WebOut
    
    ContWorkflow --> Console
    ContWorkflow --> Speaker
    ContWorkflow --> WebOut
    
    style VAWorkflow fill:#ffcdd2,stroke:#d32f2f,stroke-width:3px
    style ContWorkflow fill:#e8f5e8,stroke:#2e7d32,stroke-width:2px
    style VT fill:#ffecb3,stroke:#ff8f00,stroke-width:2px
```

### 2. –ö–æ–º–ø–æ–Ω–µ–Ω—Ç–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞

```python
class VoiceTriggerComponent(Component):
    """Voice trigger detection component - separate from ASR"""
    
    def __init__(self):
        super().__init__("voice_trigger")
        self._detector = None
        
    def get_dependencies(self) -> list[str]:
        return ["openwakeword", "numpy"]  # –ù–ï vosk/whisper
        
    async def initialize(self) -> None:
        """Initialize voice trigger detection model"""
        if not self.is_available():
            raise ComponentNotAvailable("Voice trigger dependencies not available")
        
        # Load wake word detection model
        self.logger.info("Voice trigger component initialized")
        
    async def shutdown(self) -> None:
        """Cleanup voice trigger resources"""
        if self._detector:
            await self._detector.cleanup()
        self.logger.info("Voice trigger component shutdown")
```

### 3. –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –ø–ª–∞–≥–∏–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```python
# irene/plugins/builtin/universal_voice_trigger_plugin.py
class UniversalVoiceTriggerPlugin(VoiceTriggerPlugin, WebAPIPlugin):
    """
    Universal Voice Trigger Plugin - manages multiple wake word providers
    
    Pure business logic: Audio ‚Üí Wake Word Detection Result
    Agnostic to input sources and output consumers
    
    Providers:
    - OpenWakeWordProvider (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
    - MicroWakeWordProvider (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å ESP32)
    - PicovoiceProvider (–∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ)
    - PreciseProvider (Mozilla)
    """
    
    async def detect(self, audio_data: AudioData) -> WakeWordResult:
        """Pure detection logic - no workflow knowledge"""
        provider = self.get_current_provider()
        return await provider.detect_wake_word(audio_data)
```

### 4. Workflow Orchestration Plugin

```python
# irene/plugins/builtin/voice_assistant_workflow_plugin.py
class VoiceAssistantWorkflowPlugin(CommandPlugin):
    """
    Voice Assistant Workflow Orchestrator
    
    Coordinates: Audio Input ‚Üí Voice Trigger ‚Üí ASR ‚Üí Command ‚Üí Response
    This is where the workflow logic lives, not in input sources!
    """
    
    def __init__(self):
        super().__init__()
        self.voice_trigger = None  # Injected by dependency injection
        self.asr = None           # Injected by dependency injection
        self.llm = None           # Injected by dependency injection
        self.tts = None           # Injected by dependency injection
        
    async def initialize(self):
        """Initialize with injected universal plugins"""
        # Dependency injection from PluginManager
        self.voice_trigger = self.core.plugin_manager.get_plugin("universal_voice_trigger")
        self.asr = self.core.plugin_manager.get_plugin("universal_asr")
        self.llm = self.core.plugin_manager.get_plugin("universal_llm")
        self.tts = self.core.plugin_manager.get_plugin("universal_tts")
        
    async def process_audio_stream(self, audio_stream: AsyncIterator[AudioData], context: RequestContext):
        """Main workflow orchestration logic"""
        
        async for audio_data in audio_stream:
            # Step 1: Voice trigger detection (if enabled)
            if self.voice_trigger and not context.skip_wake_word:
                wake_result = await self.voice_trigger.detect(audio_data)
                if not wake_result.detected:
                    continue  # Keep listening for wake word
                    
                self.logger.info(f"Wake word '{wake_result.word}' detected with confidence {wake_result.confidence}")
                
            # Step 2: Speech recognition
            if self.asr:
                text = await self.asr.transcribe(audio_data)
                if not text.strip():
                    continue
                    
            # Step 3: Command processing
            response = await self.process_command(text, context)
            
            # Step 4: Output routing (based on context)
            await self._route_response(response, context)
            
    async def _route_response(self, response: str, context: RequestContext):
        """Route response to appropriate output channels"""
        # TTS output (if audio response requested)
        if self.tts and context.wants_audio_response:
            audio_response = await self.tts.synthesize(response)
            await self.core.output_manager.send_audio(audio_response, context)
            
        # Text output (console, web, etc.)
        await self.core.output_manager.send_text(response, context)

# irene/plugins/builtin/continuous_listening_workflow_plugin.py  
class ContinuousListeningWorkflowPlugin(CommandPlugin):
    """
    Continuous Listening Workflow - direct ASR without wake word
    Maintains current behavior for backward compatibility
    """
    
    async def process_audio_stream(self, audio_stream: AsyncIterator[AudioData], context: RequestContext):
        """Direct ASR workflow - no wake word detection"""
        
        async for audio_data in audio_stream:
            # Direct speech recognition (current behavior)
            if self.asr:
                text = await self.asr.transcribe(audio_data)
                if not text.strip():
                    continue
                    
            # Command processing and response
            response = await self.process_command(text, context)
            await self._route_response(response, context)
```

### 5. Pure Input Sources

```python
# irene/inputs/microphone.py (CLEANED)
class MicrophoneInput(InputSource):
    """
    Pure microphone input source - no workflow knowledge
    Just captures and yields raw audio data
    """
    
    def __init__(self):
        super().__init__()
        self._audio_stream = None
        
    async def listen(self) -> AsyncIterator[AudioData]:
        """Pure audio capture - no business logic"""
        while self._listening:
            try:
                audio_chunk = await self._capture_audio()
                yield AudioData(
                    data=audio_chunk,
                    timestamp=time.time(),
                    sample_rate=self.config.sample_rate,
                    channels=self.config.channels
                )
            except Exception as e:
                self.logger.error(f"Audio capture error: {e}")
                await asyncio.sleep(0.1)
                
    async def _capture_audio(self) -> bytes:
        """Low-level audio capture implementation"""
        # Just audio capture - no workflow orchestration
        return await self._audio_stream.read()
        
    # NO knowledge of voice trigger, ASR, or workflow logic!
```

### 6. Input Manager Integration

```python
# irene/core/inputs.py (UPDATED)
class InputManager:
    """
    Input manager coordinates between input sources and workflow plugins
    Uses dependency injection to maintain loose coupling
    """
    
    async def start_voice_assistant_mode(self):
        """Start voice assistant with wake word detection"""
        # Get workflow plugin
        va_workflow = self.core.plugin_manager.get_plugin("voice_assistant_workflow")
        if not va_workflow:
            raise RuntimeError("VoiceAssistantWorkflowPlugin not available")
            
        # Get input source
        mic_input = self._get_input_source("microphone")
        if not mic_input:
            raise RuntimeError("Microphone input not available")
            
        # Connect input stream to workflow
        audio_stream = mic_input.listen()
        context = RequestContext(
            source="microphone",
            wants_audio_response=True,
            skip_wake_word=False
        )
        
        # Start workflow processing
        await va_workflow.process_audio_stream(audio_stream, context)
        
    async def start_continuous_mode(self):
        """Start continuous listening without wake word"""
        continuous_workflow = self.core.plugin_manager.get_plugin("continuous_listening_workflow")
        mic_input = self._get_input_source("microphone")
        
        audio_stream = mic_input.listen()
        context = RequestContext(
            source="microphone", 
            wants_audio_response=True,
            skip_wake_word=True
        )
        
        await continuous_workflow.process_audio_stream(audio_stream, context)
```

---

## ü§ñ **–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏**

### –ü–æ—á–µ–º—É –ù–ï –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç—É –∂–µ –º–æ–¥–µ–ª—å, —á—Ç–æ –∏ –¥–ª—è ASR

| –ê—Å–ø–µ–∫—Ç | Wake Word Detection | ASR |
|--------|-------------------|-----|
| **–ó–∞–¥–∞—á–∞** | –î–µ—Ç–µ–∫—Ü–∏—è 1-3 —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö —Ñ—Ä–∞–∑ | –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–π —Ä–µ—á–∏ |
| **–†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã** | –í—Å–µ–≥–¥–∞ –≤–∫–ª—é—á–µ–Ω–∞, –Ω–∏–∑–∫–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ | –ü–æ –∑–∞–ø—Ä–æ—Å—É –ø–æ—Å–ª–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ |
| **–†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏** | –ú–∞–ª–µ–Ω—å–∫–∏–π (1-5MB) | –ë–æ–ª—å—à–æ–π (100MB-1GB) |
| **–†–µ—Å—É—Ä—Å—ã** | –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ | –†–µ—Å—É—Ä—Å–æ–µ–º–∫–∏–µ |
| **–¢–æ—á–Ω–æ—Å—Ç—å** | –í—ã—Å–æ–∫–∞—è –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Å–ª–æ–≤ | –û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ |

### –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏

#### ü•á **OpenWakeWord (–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)**

```python
# irene/providers/wake_word/openwakeword.py
class OpenWakeWordProvider(VoiceTriggerProvider):
    """
    OpenWakeWord - Modern, accurate wake word detection
    Models: alexa, hey_jarvis, hey_irene (custom trainable)
    """
    
    async def detect_wake_word(self, audio_data: AudioData) -> WakeWordResult:
        """Pure detection logic - agnostic to workflow"""
        prediction = await self._model.predict(audio_data.data)
        return WakeWordResult(
            detected=prediction.score > self.threshold,
            confidence=prediction.score,
            word=prediction.word,
            timestamp=audio_data.timestamp
        )
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- **–ì–æ—Ç–æ–≤—ã–µ –º–æ–¥–µ–ª–∏**: "alexa", "hey_jarvis" –¥–æ—Å—Ç—É–ø–Ω—ã
- **–ö–∞—Å—Ç–æ–º–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ**: –ú–æ–∂–Ω–æ –æ–±—É—á–∏—Ç—å "hey_irene", "irene"
- **–í—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å**: –ù–∏–∑–∫–∏–π —É—Ä–æ–≤–µ–Ω—å –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π
- **–ê–∫—Ç–∏–≤–Ω–∞—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞**: –•–æ—Ä–æ—à–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è
- **Python-native**: –õ–µ–≥–∫–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è

#### üèÜ **microWakeWord (ESP32 Compatible)**

```python
# irene/providers/wake_word/microwakeword.py
class MicroWakeWordProvider(VoiceTriggerProvider):
    """
    microWakeWord - Compatible with ESP32 models
    Models: medium-12-bn architecture
    """
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- **ESP32 —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å**: –¢–µ –∂–µ –º–æ–¥–µ–ª–∏, —á—Ç–æ –≤ firmware
- **–ü—Ä–æ–≤–µ—Ä–µ–Ω–æ**: –£–∂–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ ESP32 —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
- **–ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å**: –û–¥–∏–Ω–∞–∫–æ–≤–æ–µ wake word –Ω–∞ –≤—Å–µ—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö
- **TensorFlow Lite**: –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è

#### üîß **Picovoice Porcupine**

```python
# irene/providers/wake_word/picovoice.py  
class PicovoiceProvider(VoiceTriggerProvider):
    """
    Picovoice Porcupine - Commercial-grade wake word detection
    Models: Pre-built + custom training available
    """
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- **–ö–æ–º–º–µ—Ä—á–µ—Å–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ**: –û—á–µ–Ω—å –Ω–∏–∑–∫–∏–π —É—Ä–æ–≤–µ–Ω—å –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π
- **–ú—É–ª—å—Ç–∏—è–∑—ã—á–Ω–æ—Å—Ç—å**: –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
- **Edge-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è**: –†–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–æ –¥–ª—è –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–π —Ä–∞–±–æ—Ç—ã
- **–ö–∞—Å—Ç–æ–º–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ**: –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π

### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π

| Provider | –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏ | –Ø–∑—ã–∫–∏ | –ö–∞—Å—Ç–æ–º–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ | ESP32 —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å | –õ–∏—Ü–µ–Ω–∑–∏—è |
|----------|---------------|-------|-------------------|---------------------|----------|
| **OpenWakeWord** | 1-5MB | EN (–≤ –æ—Å–Ω–æ–≤–Ω–æ–º) | ‚úÖ –î–∞ | ‚ùå –ù–µ—Ç | MIT |
| **microWakeWord** | 140KB | Trainable | ‚úÖ –î–∞ | ‚úÖ –î–∞ | Apache 2.0 |
| **Porcupine** | 1-2MB | Multi | ‚úÖ –ü–ª–∞—Ç–Ω–æ | ‚ùå –ù–µ—Ç | Commercial |
| **Precise** | 20MB | EN | ‚úÖ –°–ª–æ–∂–Ω–æ | ‚ùå –ù–µ—Ç | Apache 2.0 |

---

## ‚öôÔ∏è **–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è**

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

```toml
# config.toml
[components]
microphone = true
voice_trigger = true        # –ù–û–í–´–ô: Voice trigger component
tts = true
asr = true

[components.voice_trigger]
provider = "openwakeword"           # –û—Ç–¥–µ–ª—å–Ω–æ –æ—Ç ASR
wake_words = ["irene", "jarvis"]    # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ wake words
threshold = 0.8
buffer_seconds = 1.0                # –ë—É—Ñ–µ—Ä –∞—É–¥–∏–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
timeout_seconds = 5.0               # –¢–∞–π–º–∞—É—Ç –ø–æ—Å–ª–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏

[components.voice_trigger.provider_configs.openwakeword]
model_path = "./models/wake_word/"
wake_word_models = { 
    "irene" = "custom_irene_v1.onnx",
    "jarvis" = "hey_jarvis_v2.tflite"
}

[components.asr]  
provider = "vosk"                   # –û—Ç–¥–µ–ª—å–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä
model_path = "./models/vosk/ru_large"

# –ù–û–í–´–ô: Workflow configuration
[plugins.voice_assistant_workflow]
enabled = true
default_workflow = "voice_trigger"  # or "continuous"
wake_word_timeout = 5.0
response_timeout = 10.0

[plugins.continuous_listening_workflow]
enabled = true
fallback_enabled = true             # Fallback when voice trigger unavailable

[plugins.universal_voice_trigger]
enabled = true
default_provider = "openwakeword"
providers = ["openwakeword", "microwakeword"]

[plugins.universal_voice_trigger.provider_configs.microwakeword]
model_path = "./models/microwakeword/jarvis_medium.tflite"
frame_length_ms = 30
sample_rate = 16000
```

### –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è

```bash
# Voice Trigger –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
export IRENE_COMPONENTS__VOICE_TRIGGER__PROVIDER=openwakeword
export IRENE_COMPONENTS__VOICE_TRIGGER__THRESHOLD=0.8
export IRENE_COMPONENTS__VOICE_TRIGGER__WAKE_WORDS=irene,jarvis

# Workflow –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
export IRENE_PLUGINS__VOICE_ASSISTANT_WORKFLOW__DEFAULT_WORKFLOW=voice_trigger

# –ü—É—Ç–∏ –∫ –º–æ–¥–µ–ª—è–º
export IRENE_COMPONENTS__VOICE_TRIGGER__MODEL_PATH=/opt/irene/models/wake_word/
```

---

## üîÑ **–ü–æ—Ç–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏**

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞

```mermaid
graph TB
    subgraph "üì• Pure Input Sources"
        Mic[MicrophoneInput<br/>Audio capture only]
        WebAudio[WebAudioInput<br/>Audio reception only]
        FileAudio[FileAudioInput<br/>Audio reading only]
    end
    
    subgraph "üéº Workflow Orchestration"
        VAW[VoiceAssistantWorkflow<br/>Wake Word ‚Üí ASR ‚Üí Command]
        CLW[ContinuousListeningWorkflow<br/>Direct ASR ‚Üí Command]
    end
    
    subgraph "üéØ Universal Plugins (Pure Business Logic)"
        VT[UniversalVoiceTrigger<br/>Audio ‚Üí Wake Detection]
        ASR[UniversalASR<br/>Audio ‚Üí Text]
        LLM[UniversalLLM<br/>Text ‚Üí Response]
        TTS[UniversalTTS<br/>Text ‚Üí Audio]
    end
    
    subgraph "üîß Providers"
        VT_Providers[OpenWakeWord<br/>MicroWakeWord<br/>Porcupine]
        ASR_Providers[VOSK<br/>Whisper<br/>Google Cloud]
    end
    
    subgraph "üì§ Pure Output Targets"
        Console[Console Output]
        Speaker[Audio Output]
        WebOut[Web Response]
    end
    
    Mic --> VAW
    Mic --> CLW
    WebAudio --> VAW
    FileAudio --> VAW
    
    VAW --> VT
    VAW --> ASR
    VAW --> LLM
    VAW --> TTS
    
    CLW --> ASR
    CLW --> LLM
    CLW --> TTS
    
    VT --> VT_Providers
    ASR --> ASR_Providers
    
    VAW --> Console
    VAW --> Speaker
    VAW --> WebOut
    
    CLW --> Console
    CLW --> Speaker
    CLW --> WebOut
    
    style VAW fill:#ffcdd2,stroke:#d32f2f,stroke-width:3px
    style CLW fill:#e8f5e8,stroke:#2e7d32,stroke-width:2px
    style VT fill:#ffecb3,stroke:#ff8f00,stroke-width:2px
    style ASR fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
```

### –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫–∏

```mermaid
sequenceDiagram
    participant Input as üì• Audio Input
    participant Workflow as üéº VA Workflow
    participant VT as üéØ VoiceTrigger
    participant ASR as üó£Ô∏è ASR Plugin
    participant CMD as ‚ö° Command Processor
    participant Output as üì§ Audio Output
    
    loop Continuous Audio Stream
        Input->>Workflow: Audio chunk
        Workflow->>VT: Check wake word
        VT->>VT: Pure detection logic
        alt Wake word detected
            VT->>Workflow: Wake detected
            Workflow->>ASR: Transcribe audio
            ASR->>Workflow: Text result
            Workflow->>CMD: Process command
            CMD->>Workflow: Command result
            Workflow->>Output: Route response
        else No wake word
            VT->>Workflow: No wake word
            Workflow->>Input: Continue listening
        end
    end
    
    Note over Workflow: Orchestration logic here<br/>NOT in input sources
    Note over VT,ASR: Pure business logic<br/>Agnostic to workflow
```

---

## üåê **Web API Integration**

### –ù–æ–≤—ã–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã

```python
# Web API —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –≤ UniversalVoiceTriggerPlugin
@app.post("/voice_trigger/detect")
async def detect_wake_word(audio: UploadFile):
    """Test wake word detection on uploaded audio"""
    
@app.post("/voice_trigger/train")
async def train_wake_word(samples: List[UploadFile], wake_word: str):
    """Train custom wake word model"""
    
@app.get("/voice_trigger/status")
async def voice_trigger_status():
    """Get voice trigger detection status and stats"""
    
@app.get("/voice_trigger/providers")
async def list_providers():
    """List available voice trigger providers"""
    
@app.post("/voice_trigger/threshold")
async def set_threshold(threshold: float):
    """Update detection threshold"""

# Workflow management endpoints
@app.post("/workflow/start_voice_assistant")
async def start_voice_assistant_mode():
    """Start voice assistant workflow with wake word"""
    
@app.post("/workflow/start_continuous")
async def start_continuous_mode():
    """Start continuous listening workflow"""
    
@app.get("/workflow/status")
async def workflow_status():
    """Get current workflow status"""
```

---

## üöÄ **–ü–ª–∞–Ω —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏**

### Phase 1: Core Infrastructure
1. ‚úÖ –°–æ–∑–¥–∞—Ç—å `VoiceTriggerComponent` –≤ `irene/core/components.py`
2. ‚úÖ –°–æ–∑–¥–∞—Ç—å `VoiceTriggerProvider` –±–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –≤ `irene/providers/wake_word/base.py`
3. ‚úÖ –î–æ–±–∞–≤–∏—Ç—å voice trigger –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≤ `irene/config/models.py`
4. ‚úÖ –û–±–Ω–æ–≤–∏—Ç—å `ComponentManager` –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ voice trigger

### Phase 2: Workflow Orchestration
1. üîÑ –°–æ–∑–¥–∞—Ç—å `VoiceAssistantWorkflowPlugin` (–ù–û–í–´–ô –ü–†–ò–û–†–ò–¢–ï–¢)
2. üîÑ –°–æ–∑–¥–∞—Ç—å `ContinuousListeningWorkflowPlugin` –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
3. üîÑ –û–±–Ω–æ–≤–∏—Ç—å `InputManager` –¥–ª—è workflow coordination
4. üîÑ –î–æ–±–∞–≤–∏—Ç—å workflow –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é

### Phase 3: Provider Implementation
1. üîÑ –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å `OpenWakeWordProvider` (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
2. üîÑ –î–æ–±–∞–≤–∏—Ç—å `MicroWakeWordProvider` –∫–∞–∫ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—É
3. üîÑ –°–æ–∑–¥–∞—Ç—å —Å–∏—Å—Ç–µ–º—É –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π
4. üîÑ –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å —Å asset management —Å–∏—Å—Ç–µ–º–æ–π

### Phase 4: Integration
1. üîÑ –°–æ–∑–¥–∞—Ç—å `UniversalVoiceTriggerPlugin`
2. üîÑ –û–±–Ω–æ–≤–∏—Ç—å `ComponentManager` –∏ deployment profiles
3. üîÑ –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –æ–±–∞ workflow —Ä–µ–∂–∏–º–∞
4. üîÑ –û–±–µ—Å–ø–µ—á–∏—Ç—å graceful fallback –º–µ–∂–¥—É —Ä–µ–∂–∏–º–∞–º–∏

### Phase 5: Web API & Tools
1. üîÑ –î–æ–±–∞–≤–∏—Ç—å voice trigger Web API —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã
2. üîÑ –°–æ–∑–¥–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –æ–±—É—á–µ–Ω–∏—è/—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è wake word
3. üîÑ –î–æ–±–∞–≤–∏—Ç—å workflow management API
4. üîÑ –°–æ–∑–¥–∞—Ç—å –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è workflows

### Phase 6: ESP32 Integration
1. üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è ESP32 TensorFlow Lite –º–æ–¥–µ–ª–µ–π –≤ Python-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Ñ–æ—Ä–º–∞—Ç
2. üîÑ –û–±—â–∏–π –ø–∞–π–ø–ª–∞–π–Ω –æ–±—É—á–µ–Ω–∏—è wake word –º–µ–∂–¥—É ESP32 –∏ Python
3. üîÑ –£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç wake word –º–æ–¥–µ–ª–µ–π –≤ —ç–∫–æ—Å–∏—Å—Ç–µ–º–µ

---

## üì¶ **–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏**

### –ì—Ä—É–ø–ø—ã –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
# –ë–∞–∑–æ–≤–∞—è voice trigger —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å
uv add irene-voice-assistant[voice-trigger]

# OpenWakeWord (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
uv add openwakeword torch torchaudio

# MicroWakeWord (ESP32 —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å)
uv add microwakeword tensorflow-lite

# Picovoice Porcupine (–∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–π)
uv add pvporcupine

# –ü–æ–ª–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å voice trigger
uv add irene-voice-assistant[voice,voice-trigger]
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å voice trigger –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
python -m irene.runners.cli --check-voice-trigger

# –ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç—É—Å voice trigger
python -c "from irene.utils.loader import get_voice_trigger_status; print(get_voice_trigger_status())"

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å workflow –ø–ª–∞–≥–∏–Ω—ã
python -m irene.runners.cli --check-workflows
```

---

## üîß **Deployment Profiles Update**

### –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –ø—Ä–æ—Ñ–∏–ª–∏ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è

```python
# –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ deployment profiles –≤ ComponentManager
def get_deployment_profile(self) -> str:
    available = set(self._components.keys())
    workflows = self._get_available_workflows()
    
    if {"microphone", "voice_trigger", "asr", "tts", "web_api"} <= available:
        if "voice_assistant_workflow" in workflows:
            return "Smart Voice Assistant"      # –ù–û–í–´–ô: Voice trigger + workflow
        else:
            return "Voice Assistant (Basic)"   # Components –Ω–æ –Ω–µ—Ç workflow
    elif {"microphone", "asr", "tts", "web_api"} <= available:
        if "continuous_listening_workflow" in workflows:
            return "Continuous Voice Assistant" # –¢–µ–∫—É—â–µ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ
        else:
            return "Voice Assistant (Limited)"
    elif {"voice_trigger", "web_api"} <= available:
        return "Voice Trigger API Server"   # –ù–û–í–´–ô: –¢–æ–ª—å–∫–æ voice trigger API
    elif "web_api" in available:
        return "API Server"
    else:
        return "Headless"

def _get_available_workflows(self) -> set[str]:
    """Get available workflow plugins"""
    workflows = set()
    if self.core.plugin_manager.has_plugin("voice_assistant_workflow"):
        workflows.add("voice_assistant_workflow")
    if self.core.plugin_manager.has_plugin("continuous_listening_workflow"):
        workflows.add("continuous_listening_workflow")
    return workflows
```

---

## üéØ **–ö–ª—é—á–µ–≤—ã–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ô –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã**

1. **‚úÖ Separation of Concerns**: Input sources —á–∏—Å—Ç—ã–µ, workflow –ª–æ–≥–∏–∫–∞ –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–∞
2. **‚úÖ Loose Coupling**: Universal plugins –∞–≥–Ω–æ—Å—Ç–∏—á–Ω—ã –∫ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º –∏ –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—è–º
3. **‚úÖ Testability**: –ö–∞–∂–¥—ã–π —Å–ª–æ–π —Ç–µ—Å—Ç–∏—Ä—É–µ—Ç—Å—è –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ
4. **‚úÖ Reusability**: TTS/ASR –ø–ª–∞–≥–∏–Ω—ã —Ä–∞–±–æ—Ç–∞—é—Ç —Å –ª—é–±—ã–º–∏ workflows
5. **‚úÖ Flexibility**: –õ–µ–≥–∫–æ –¥–æ–±–∞–≤–ª—è—Ç—å –Ω–æ–≤—ã–µ workflow —Ç–∏–ø—ã
6. **‚úÖ Maintainability**: –ß–∏—Å—Ç—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã –º–µ–∂–¥—É –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏
7. **‚úÖ Backward Compatibility**: Continuous workflow —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç–µ–∫—É—â–µ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ
8. **‚úÖ Graceful Degradation**: –°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ voice trigger –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞

---

## üéì **–û–±—É—á–µ–Ω–∏–µ Wake Word –º–æ–¥–µ–ª–µ–π**

### –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –æ–±—É—á–µ–Ω–∏—è

VoiceTrigger –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω —Å —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π –æ–±—É—á–µ–Ω–∏—è wake word –º–æ–¥–µ–ª–µ–π:

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏ –æ–±—É—á–µ–Ω–∏—è (if working in project directory)
uv sync --extra wake-word-training

# Or if installing as external package:
# uv add irene-voice-assistant[wake-word-training]

# –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
irene-record-samples --wake_word irene --speaker_name your_name --num_samples 50
irene-train-wake-word irene --epochs 55 --batch_size 16
irene-validate-model models/irene_medium_*.tflite

# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
irene-convert-to-onnx models/irene_medium_*.tflite    # ‚Üí OpenWakeWord
irene-convert-to-tflite models/irene_medium_*.tflite  # ‚Üí Python microWakeWord
irene-convert-to-esp32 models/irene_medium_*.tflite   # ‚Üí ESP32 firmware
```

### –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π

| –¢–∏–ø –æ–±—É—á–µ–Ω–∏—è | OpenWakeWord Provider | MicroWakeWord Provider | ESP32 Firmware |
|-------------|---------------------|----------------------|----------------|
| **microWakeWord** | ‚úÖ Via ONNX | ‚úÖ Native TFLite | ‚úÖ Native C headers |
| **OpenWakeWord** | ‚úÖ Native ONNX | ‚ùå –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ç—Ä–µ–±—É–µ—Ç—Å—è | ‚ùå –ù–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è |
| **Custom Training** | ‚úÖ ONNX export | ‚úÖ TFLite export | ‚úÖ C header export |

### –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ –æ–±—É—á–µ–Ω–∏—é

- **–ü–æ–ª–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ**: `wake_word_training/README.md`
- **–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è**: `wake_word_training/USAGE_EXAMPLE.md`
- **ESP32 –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è**: `ESP32/firmware/GETTING_STARTED.md`

---

## üìû **–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π**

–≠—Ç–æ—Ç **–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô** –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ø—Ä–∏–Ω—Ü–∏–ø–∞–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã Irene v13:

- ‚úÖ **–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã** —Å graceful degradation
- ‚úÖ **Universal Plugin + Provider** –ø–∞—Ç—Ç–µ—Ä–Ω —Å —á–∏—Å—Ç—ã–º —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º
- ‚úÖ **Workflow Orchestration** –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Å–ª–æ–π –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏
- ‚úÖ **–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞** –Ω–∞ –≤—Å–µ—Ö —É—Ä–æ–≤–Ω—è—Ö
- ‚úÖ **Web API –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è** —Å —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞–º–∏
- ‚úÖ **–ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º–æ—Å—Ç—å** —á–µ—Ä–µ–∑ TOML/ENV
- ‚úÖ **–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—å** (CLI, voice, web –æ—Å—Ç–∞—é—Ç—Å—è –¥–æ—Å—Ç—É–ø–Ω—ã–º–∏)
- ‚úÖ **Dependency Injection** –∏ —á–∏—Å—Ç–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
- ‚úÖ **Single Responsibility Principle** –Ω–∞ –∫–∞–∂–¥–æ–º —É—Ä–æ–≤–Ω–µ

–≠—Ç–æ—Ç –¥–∏–∑–∞–π–Ω –∑–∞–ø–æ–ª–Ω—è–µ—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π –ø—Ä–æ–±–µ–ª –∏ –ø—Ä–∏–≤–æ–¥–∏—Ç Python —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é –∫ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–º—É –ø–∞—Ä–∏—Ç–µ—Ç—É —Å ESP32 firmware, **—Å–æ—Ö—Ä–∞–Ω—è—è –ø—Ä–∏ —ç—Ç–æ–º —á–∏—Å—Ç—É—é v13 –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –±–µ–∑ –Ω–∞—Ä—É—à–µ–Ω–∏—è –ø—Ä–∏–Ω—Ü–∏–ø–æ–≤ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏**. 